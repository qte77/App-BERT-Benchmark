{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qte77/ML/blob/main_CU-042621/HF-WnB-PoC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9FNxduh6_Wy"
      },
      "source": [
        "# HuggingFace PoC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehFDdQ50qUrV"
      },
      "source": [
        "## Links\n",
        "* [Matthias Bussonnier pip_magic repository](https://github.com/Carreau/pip_magic), e.g. `!jupyter kernelspec list`\n",
        "* [Installing Python Packages from a Jupyter Notebook](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n0-plwup1Lh"
      },
      "source": [
        "## System info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KG0MlekpNU8"
      },
      "outputs": [],
      "source": [
        "!type -a python\n",
        "!type -a pip\n",
        "!type -a pip3\n",
        "!jupyter kernelspec list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r8jF8qB6l3o"
      },
      "source": [
        "## Install and load modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgAzuM-i62-g"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYCpUZ1W4Lf1"
      },
      "outputs": [],
      "source": [
        "#!{sys.executable} -m pip3 install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX0VkWdWbCrc"
      },
      "outputs": [],
      "source": [
        "#no module pip3\n",
        "!{sys.executable} -m pip install -qqq wandb\n",
        "#remove version from wandb\n",
        "!{sys.executable} -m pip  uninstall -yyy -qqq folium\n",
        "!{sys.executable} -m pip  install -qqq 'folium == 0.2.1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqDgj5DDbt0c"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m pip install -qqq datasets transformers bert_score\n",
        "# Optional -> install latest version from source\n",
        "#!{sys.executable} -m pip3 install -qqq git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vYY5STcVr0m"
      },
      "outputs": [],
      "source": [
        "#setuptools, freeze, \n",
        "!{sys.executable} -m pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBD3Isr1hxHx"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, list_datasets, list_metrics\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import load_metric\n",
        "import wandb\n",
        "import bert_score\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MksaV-AaREM"
      },
      "outputs": [],
      "source": [
        "#run_glue.py\n",
        "#!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl_2wkh-qv9g"
      },
      "source": [
        "## Connect to WandB\n",
        "* [Get key here](https://wandb.ai/authorize) or in section `API keys` of [the settings](https://wandb.ai/settings)\n",
        "* specify parameters like the dataset to use\n",
        "* specify wandb-env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAO0xBD4aREP"
      },
      "outputs": [],
      "source": [
        "!wandb login --relogin\n",
        "#wandb.login()\n",
        "#wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1gpEyMXhUPt"
      },
      "outputs": [],
      "source": [
        "taskname='mrpc'\n",
        "project='BERT-MRPC-GPU'\n",
        "entity='ba'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFqGFmzkaREQ"
      },
      "outputs": [],
      "source": [
        "#https://docs.wandb.ai/guides/track/advanced/environment-variables\n",
        "%env WANDB_WATCH=\"all\"\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_PROJECT=f'{project}'\n",
        "%env WANDB_ENTITY=f'{entity}'\n",
        "%env WANDB_SAVE_CODE=true\n",
        "#avoid error:\n",
        "#The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
        "%env TOKENIZERS_PARALLELISM=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23tFXLEz6vT8"
      },
      "source": [
        "## Use run_glue.py as wrapper\n",
        "\n",
        "Notiz: WandB loggt beim Wrapper nur die Systemdaten und nicht auch die vom Modell.\n",
        "Recherche n√∂tig oder direkt API nutzen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A5kKkdiaRER"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'yahoo': 'distilbert-base-uncased',\n",
        "    'mrpc': 'bert-base-uncased'\n",
        "}\n",
        "model = models.get(taskname)\n",
        "\n",
        "!python run_glue.py \\\n",
        "  --report_to wandb \\\n",
        "  --model_name_or_path model \\\n",
        "  --task_name taskname \\\n",
        "  --learning_rate 1e-4 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --max_steps 300 \\\n",
        "  --logging_steps 30 \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --output_dir f'/tmp/{taskname}' \\\n",
        "  --overwrite_output_dir \\\n",
        "  --run_name taskname\n",
        "#  --remove_unused_columns False\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQ5ylSAaREV"
      },
      "source": [
        "## Use API without wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0OJx-l7tSww"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8P4zNGdkUsU"
      },
      "outputs": [],
      "source": [
        "dataset_param = {\n",
        "    'yahoo': ['yahoo_answers_topics','','topic','distilbert-base-uncased'],\n",
        "    'mrpc': ['glue','mrpc','label','bert-base-uncased']\n",
        "}\n",
        "ds_col, ds_name, dscol_rename, mod = dataset_param.get(taskname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56BV_YDiaREW"
      },
      "outputs": [],
      "source": [
        "#list_datasets()\n",
        "#load_ds also also splits into train/eval\n",
        "dataset = load_dataset(ds_col, ds_name)\n",
        "label_list = dataset['train'].unique(dscol_rename)\n",
        "num_labels = len(label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWCL947gaREX"
      },
      "outputs": [],
      "source": [
        "dataset.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGCwHuW2aREb"
      },
      "outputs": [],
      "source": [
        "#rename label/topci column to 'labels' for model args input\n",
        "for name in dataset:\n",
        "  if dscol_rename in dataset[name].column_names:\n",
        "    dataset[name] = dataset[name].rename_column(dscol_rename, 'labels')\n",
        "  else:\n",
        "    print(\"Attribute/Feature/Column '%s' not found in '%s'. Found:\" % (dscol_rename, name))\n",
        "\n",
        "  print(dataset[name].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-dBfXYCaREb"
      },
      "source": [
        "### Tokenize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYFC9kUKaREc"
      },
      "outputs": [],
      "source": [
        "# try max_length=X, try fast=False\n",
        "tokenizer = AutoTokenizer.from_pretrained(mod, use_fast=True, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9zhKAE_aREc"
      },
      "outputs": [],
      "source": [
        "#sample_input = dataset['train'][0]\n",
        "#sample_input\n",
        "#tokenizer(sample_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZJFGgCsaREd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset_mrpc.map(tokenize_function, batched=True)\n",
        "'''\n",
        "#tokenizing and padding\n",
        "#try tokenizer(padding=\"max_length\", max_length=X)\n",
        "if taskname == 'yahoo':\n",
        "  tokenized_datasets = dataset.map(lambda x: tokenizer(\n",
        "      x['question_title'], truncation=True), batched=True\n",
        "    ).remove_columns(\n",
        "      ['question_title', 'id', 'best_answer', 'question_content']\n",
        "    )\n",
        "elif taskname == 'mrpc':\n",
        "  tokenized_datasets = dataset.map(lambda x: tokenizer(\n",
        "      x['sentence1'], x['sentence2'], truncation=True\n",
        "    ), batched=True).remove_columns(\n",
        "      ['sentence1', 'sentence2', 'idx']\n",
        "    )\n",
        "else:\n",
        "  print('Not found.')\n",
        "\n",
        "tokenized_datasets.column_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeszXRDz69hS"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwYHsF3LaREf"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(mod, num_labels=num_labels)\n",
        "print(model.config)\n",
        "print(model.bert.embeddings)\n",
        "print(model.bert.encoder.layer[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oLJUue6aREg"
      },
      "outputs": [],
      "source": [
        "#yahoo\n",
        "#import torch\n",
        "'''\n",
        "def get_topic(sentence, tokenize=tokenizer, model=model):\n",
        "    # tokenize the input\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    # ensure model and inputs are on the same device (GPU)\n",
        "    inputs = {name: tensor.cuda() for name, tensor in inputs.items()}\n",
        "    model = model.cuda()\n",
        "    # get prediction - 10 classes \"probabilities\" (not really true because they still need to be normalized)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(**inputs)[0].cpu().numpy()\n",
        "    # get the top prediction class and convert it to its associated label\n",
        "    top_prediction = predictions.argmax().item()\n",
        "    return dataset['train'].features['labels'].int2str(top_prediction)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDZUFWHEaREh"
      },
      "outputs": [],
      "source": [
        "#yahoo\n",
        "#get_topic('Why is cheese so much better with wine?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okVeNo3GaREi"
      },
      "source": [
        "### Training Arguments\n",
        "[HF args documentation](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8L66MvXaREi"
      },
      "outputs": [],
      "source": [
        "lr=5e-6\n",
        "max_steps=3000\n",
        "\n",
        "eval_steps=round(max_steps/5)\n",
        "save_steps=round(eval_steps*2)\n",
        "\n",
        "#PyTorch: setting up devices\n",
        "args = TrainingArguments(\n",
        "    report_to = 'wandb',                     # enable logging to W&B\n",
        "    output_dir = taskname,\n",
        "    overwrite_output_dir = True,\n",
        "    evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
        "    learning_rate = lr,                   # we can customize learning rate\n",
        "    max_steps = max_steps,\n",
        "    logging_steps = 100,                    # we will log every 100 steps\n",
        "    eval_steps = eval_steps,                      # we will perform evaluation every 5000 steps\n",
        "    save_steps = save_steps,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'accuracy',\n",
        "    run_name = taskname,           # name of the W&B run\n",
        "#    remove_unused_columns = True  # avoid warning 'The following columns in the evaluation set  don't have a corresponding argument'\n",
        ")\n",
        "args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ppzQnQfaREj"
      },
      "source": [
        "### Custom Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdxEd6etsa_Q"
      },
      "outputs": [],
      "source": [
        "#list_metrics()\n",
        "#downloading metrics builder scripts\n",
        "#bertscore = load_metric('bertscore')\n",
        "metrics_to_load = ['accuracy','precision','recall','f1','mae','mse']\n",
        "loaded_metrics = []\n",
        "metrics_calc = []\n",
        "\n",
        "for met in metrics_to_load:\n",
        "  loaded_metrics.append(load_metric(met))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyCFxyx_aREj"
      },
      "outputs": [],
      "source": [
        "#define custom metrics\n",
        "#datasets.list_metrics()\n",
        "#F1 = 2 * (precision * recall) / (precision + recall)\n",
        "#Recall = TP / (TP + FN)\n",
        "#bertscore: bert_score needs to be installed\n",
        "#   cosine-similarity, precision, recall, F1\n",
        "#glue: cfg names [\"sst2\", \"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"cola\", \"stsb\", \"mrpc\", \"qqp\", \"qnli\", \"rte\", \"wnli\", \"hans\"]'\n",
        "#glue mrpc: accuracy, f1\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1) #predictions.argmax(-1)\n",
        "  \n",
        "  for i, met in enumerate(loaded_metrics):\n",
        "    metrics_calc[i] = met.compute(predictions=predictions, references=labels)\n",
        "\n",
        "  print(\"*************\")\n",
        "  for met in metrics_calc:\n",
        "    wandb.log(met)\n",
        "    print(met)\n",
        "  print(\"*************\")  \n",
        "\n",
        "  return metrics_calc[metrics_to_load.index('accuracy')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEN8kz20rLQf"
      },
      "source": [
        "### Build trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gsvb1lBaREk"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "  model = model,\n",
        "  args = args,\n",
        "  train_dataset=tokenized_datasets['train'],\n",
        "  eval_dataset=tokenized_datasets['test'],\n",
        "  tokenizer=tokenizer,            # for padding batched data\n",
        "  compute_metrics=compute_metrics # for custom metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoqnidhpeHph"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=project, entity=entity, save_code = True)\n",
        "#!wandb init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENka0ii77PnF"
      },
      "source": [
        "### Pre-evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy0vbU1NaREk"
      },
      "outputs": [],
      "source": [
        "#trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SesM0ZdaREl"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n5R4b2laREl"
      },
      "outputs": [],
      "source": [
        "#import torch\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"*************\")\n",
        "print(\"Taskname: %s, Labels#: %s, lr: %s\" % (taskname, num_labels, lr))\n",
        "#print(os.environ)\n",
        "print(\"*************\")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZd_HFUe7cZ_"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmUce_jwaREp"
      },
      "outputs": [],
      "source": [
        "#yahoo\n",
        "#get_topic('Why is cheese so much better with wine?')\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9f8giJBccbA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "pa_Hugging_Face_models_wnb.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "a2c38984cde13219f5762decb43eb3d0c702ceca3242c525e06c46c0c4b9d01c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
